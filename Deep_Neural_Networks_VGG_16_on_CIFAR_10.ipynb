{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/0x-s13i/deep-neural-networks/blob/main/Deep_Neural_Networks_VGG_16_on_CIFAR_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import sys\n",
        "# print(sys.version)"
      ],
      "metadata": {
        "id": "RriyYaQEOB3A"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pFhI6N1f1y67"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import numpy as np\n",
        "import random as random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NaqxuKYX5UEs"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hVzv08rw5ZUV"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "num_epochs = 100\n",
        "learning_rate = 0.001\n",
        "batch_size = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "eP5hq6tvANQg"
      },
      "outputs": [],
      "source": [
        "# Define a transform that applies data augmentation techniques\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomCrop(36, padding=4),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105,
          "referenced_widgets": [
            "7edb6c23502f40f2a687206c0128fd16",
            "6293a9e370c3489d865cd669653364cd",
            "b98fe8f73032479ab17369c353268d46",
            "25249f861ce74e3481ae3ea116c281a2",
            "b13e0796cee149f284270f7b50a59c25",
            "c8aa02ca90fb471b99796b3c3aef2a3f",
            "0fde248261c448cca20dbdef69b24c5b",
            "82abaa49ad584d7180889c22c5288a7e",
            "e30ce103f87e45a8bf462ee7ad8c24df",
            "4e7a041fcf344c71ab82d41bb50162de",
            "3a240b8d66dc4faea5ecae8db7756d8e"
          ]
        },
        "id": "X3XhTxwe7n7t",
        "outputId": "4edc9c5c-6225-4b78-c67a-51fd2fc3f7fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../../data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7edb6c23502f40f2a687206c0128fd16"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../../data/cifar-10-python.tar.gz to ../../data\n"
          ]
        }
      ],
      "source": [
        "# CIFAR-10 dataset\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='../../data',\n",
        "                                             train=True, \n",
        "                                             transform=transform,\n",
        "                                             download=True)\n",
        "\n",
        "# Split the training dataset into train and validation datasets\n",
        "train_ratio = 0.9\n",
        "val_ratio = 0.1\n",
        "train_size = int(train_ratio * len(train_dataset))\n",
        "val_size = int(val_ratio * len(train_dataset))\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='../../data',\n",
        "                                            train=False, \n",
        "                                            transform=transform)\n",
        "\n",
        "# Create DataLoaders for the datasets\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ZN7Uw_LO8kIH"
      },
      "outputs": [],
      "source": [
        "# Setting fixed seed for random generator so that results are reproducible\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "random.seed(0)\n",
        "\n",
        "\n",
        "class VGG16(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        # Initialize the base model\n",
        "        super(VGG16, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv4 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "        self.conv5 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv6 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv7 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool3 = nn.MaxPool2d(2)\n",
        "        self.conv8 = nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv9 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv10 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool4 = nn.MaxPool2d(2)\n",
        "        self.conv11 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv12 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv13 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool5 = nn.MaxPool2d(2)\n",
        "        self.fc1 = nn.Linear(512 * 1 * 1, 4096)\n",
        "        self.fc2 = nn.Linear(4096, 4096)\n",
        "        self.fc3 = nn.Linear(4096, num_classes)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        # self.softmax = nn.Softmax(-1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Perform forward pass\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool2(x)\n",
        "        \n",
        "        x = self.conv5(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv6(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv7(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool3(x)\n",
        "        \n",
        "        x = self.conv8(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv9(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv10(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool4(x)\n",
        "        \n",
        "        x = self.conv11(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv12(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv13(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool5(x)\n",
        "        \n",
        "        # Flatten the output of the convolutional layers        \n",
        "        x = x.view(-1, 512 * 1 * 1)\n",
        "\n",
        "        # Pass the flattened tensor through the fully-connected layers\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc3(x)\n",
        "        # x = self.softmax(x)\n",
        "        \n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "UnxBP8u0A7lv"
      },
      "outputs": [],
      "source": [
        "# Instantiate the model\n",
        "model = VGG16()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "RoM2LTF3BASC"
      },
      "outputs": [],
      "source": [
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.SGD(model.parameters(), lr=learning_rate, weight_decay=5e-4*batch_size, momentum=0.9, nesterov=True)\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bGAvOfKJ84Q",
        "outputId": "779d1d03-5fcb-463f-b625-61ee6c9c143a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100], Step [100/351], Loss: 2.0886\n",
            "Epoch [1/100], Step [200/351], Loss: 1.9545\n",
            "Epoch [1/100], Step [300/351], Loss: 1.8097\n",
            "Epoch [2/100], Step [100/351], Loss: 1.8625\n",
            "Epoch [2/100], Step [200/351], Loss: 1.8232\n",
            "Epoch [2/100], Step [300/351], Loss: 1.6391\n",
            "Epoch [3/100], Step [100/351], Loss: 1.8292\n",
            "Epoch [3/100], Step [200/351], Loss: 1.4475\n",
            "Epoch [3/100], Step [300/351], Loss: 1.5224\n",
            "Epoch [4/100], Step [100/351], Loss: 1.4966\n",
            "Epoch [4/100], Step [200/351], Loss: 1.3702\n",
            "Epoch [4/100], Step [300/351], Loss: 1.3174\n",
            "Epoch [5/100], Step [100/351], Loss: 1.1524\n",
            "Epoch [5/100], Step [200/351], Loss: 0.9947\n",
            "Epoch [5/100], Step [300/351], Loss: 1.2430\n",
            "Epoch [6/100], Step [100/351], Loss: 0.9412\n",
            "Epoch [6/100], Step [200/351], Loss: 1.2008\n",
            "Epoch [6/100], Step [300/351], Loss: 1.0521\n",
            "Epoch [7/100], Step [100/351], Loss: 1.0012\n",
            "Epoch [7/100], Step [200/351], Loss: 1.1614\n",
            "Epoch [7/100], Step [300/351], Loss: 0.8823\n",
            "Epoch [8/100], Step [100/351], Loss: 0.9361\n",
            "Epoch [8/100], Step [200/351], Loss: 0.8843\n",
            "Epoch [8/100], Step [300/351], Loss: 0.8537\n",
            "Epoch [9/100], Step [100/351], Loss: 0.8662\n",
            "Epoch [9/100], Step [200/351], Loss: 0.7020\n",
            "Epoch [9/100], Step [300/351], Loss: 0.6194\n",
            "Epoch [10/100], Step [100/351], Loss: 0.7063\n",
            "Epoch [10/100], Step [200/351], Loss: 0.5608\n",
            "Epoch [10/100], Step [300/351], Loss: 0.7345\n",
            "Epoch [11/100], Step [100/351], Loss: 0.8406\n",
            "Epoch [11/100], Step [200/351], Loss: 0.6444\n",
            "Epoch [11/100], Step [300/351], Loss: 0.7715\n",
            "Epoch [12/100], Step [100/351], Loss: 0.8062\n",
            "Epoch [12/100], Step [200/351], Loss: 0.7266\n",
            "Epoch [12/100], Step [300/351], Loss: 0.5761\n",
            "Epoch [13/100], Step [100/351], Loss: 0.6795\n",
            "Epoch [13/100], Step [200/351], Loss: 0.6136\n",
            "Epoch [13/100], Step [300/351], Loss: 0.7376\n",
            "Epoch [14/100], Step [100/351], Loss: 0.5527\n",
            "Epoch [14/100], Step [200/351], Loss: 0.6459\n",
            "Epoch [14/100], Step [300/351], Loss: 0.7242\n",
            "Epoch [15/100], Step [100/351], Loss: 0.5272\n",
            "Epoch [15/100], Step [200/351], Loss: 1.2456\n",
            "Epoch [15/100], Step [300/351], Loss: 1.1246\n",
            "Epoch [16/100], Step [100/351], Loss: 0.7156\n",
            "Epoch [16/100], Step [200/351], Loss: 0.6824\n",
            "Epoch [16/100], Step [300/351], Loss: 0.4471\n",
            "Epoch [17/100], Step [100/351], Loss: 0.5874\n",
            "Epoch [17/100], Step [200/351], Loss: 0.4766\n",
            "Epoch [17/100], Step [300/351], Loss: 0.5614\n",
            "Epoch [18/100], Step [100/351], Loss: 0.5525\n",
            "Epoch [18/100], Step [200/351], Loss: 0.3801\n",
            "Epoch [18/100], Step [300/351], Loss: 0.5352\n",
            "Epoch [19/100], Step [100/351], Loss: 0.5672\n",
            "Epoch [19/100], Step [200/351], Loss: 0.8153\n",
            "Epoch [19/100], Step [300/351], Loss: 0.3538\n",
            "Epoch [20/100], Step [100/351], Loss: 0.4393\n",
            "Epoch [20/100], Step [200/351], Loss: 0.6803\n",
            "Epoch [20/100], Step [300/351], Loss: 0.7038\n",
            "Epoch [21/100], Step [100/351], Loss: 0.5150\n",
            "Epoch [21/100], Step [200/351], Loss: 0.2979\n",
            "Epoch [21/100], Step [300/351], Loss: 0.4656\n",
            "Epoch [22/100], Step [100/351], Loss: 0.3959\n",
            "Epoch [22/100], Step [200/351], Loss: 0.5635\n",
            "Epoch [22/100], Step [300/351], Loss: 0.5236\n",
            "Epoch [23/100], Step [100/351], Loss: 0.6247\n",
            "Epoch [23/100], Step [200/351], Loss: 0.4631\n",
            "Epoch [23/100], Step [300/351], Loss: 0.4711\n",
            "Epoch [24/100], Step [100/351], Loss: 0.5273\n",
            "Epoch [24/100], Step [200/351], Loss: 0.4280\n",
            "Epoch [24/100], Step [300/351], Loss: 0.5199\n",
            "Epoch [25/100], Step [100/351], Loss: 0.4808\n",
            "Epoch [25/100], Step [200/351], Loss: 0.4822\n",
            "Epoch [25/100], Step [300/351], Loss: 0.3743\n",
            "Epoch [26/100], Step [100/351], Loss: 0.5247\n",
            "Epoch [26/100], Step [200/351], Loss: 0.4183\n",
            "Epoch [26/100], Step [300/351], Loss: 0.5250\n",
            "Epoch [27/100], Step [100/351], Loss: 0.4475\n",
            "Epoch [27/100], Step [200/351], Loss: 0.6183\n",
            "Epoch [27/100], Step [300/351], Loss: 0.5144\n",
            "Epoch [28/100], Step [100/351], Loss: 0.4908\n",
            "Epoch [28/100], Step [200/351], Loss: 0.4394\n",
            "Epoch [28/100], Step [300/351], Loss: 0.3649\n",
            "Epoch [29/100], Step [100/351], Loss: 0.5395\n",
            "Epoch [29/100], Step [200/351], Loss: 0.4645\n",
            "Epoch [29/100], Step [300/351], Loss: 0.2836\n",
            "Epoch [30/100], Step [100/351], Loss: 0.2258\n",
            "Epoch [30/100], Step [200/351], Loss: 0.4763\n",
            "Epoch [30/100], Step [300/351], Loss: 0.3753\n",
            "Epoch [31/100], Step [100/351], Loss: 0.5307\n",
            "Epoch [31/100], Step [200/351], Loss: 0.4496\n",
            "Epoch [31/100], Step [300/351], Loss: 0.4825\n",
            "Epoch [32/100], Step [100/351], Loss: 0.3797\n",
            "Epoch [32/100], Step [200/351], Loss: 0.3006\n",
            "Epoch [32/100], Step [300/351], Loss: 0.8601\n",
            "Epoch [33/100], Step [100/351], Loss: 0.8067\n",
            "Epoch [33/100], Step [200/351], Loss: 0.4300\n",
            "Epoch [33/100], Step [300/351], Loss: 0.5777\n",
            "Epoch [34/100], Step [100/351], Loss: 0.4147\n",
            "Epoch [34/100], Step [200/351], Loss: 0.6257\n",
            "Epoch [34/100], Step [300/351], Loss: 0.4192\n",
            "Epoch [35/100], Step [100/351], Loss: 0.6199\n",
            "Epoch [35/100], Step [200/351], Loss: 0.4817\n",
            "Epoch [35/100], Step [300/351], Loss: 0.5359\n",
            "Epoch [36/100], Step [100/351], Loss: 0.4029\n",
            "Epoch [36/100], Step [200/351], Loss: 0.3921\n",
            "Epoch [36/100], Step [300/351], Loss: 0.5297\n",
            "Epoch [37/100], Step [100/351], Loss: 0.5316\n",
            "Epoch [37/100], Step [200/351], Loss: 0.4131\n",
            "Epoch [37/100], Step [300/351], Loss: 0.4190\n",
            "Epoch [38/100], Step [100/351], Loss: 0.3695\n",
            "Epoch [38/100], Step [200/351], Loss: 0.3009\n",
            "Epoch [38/100], Step [300/351], Loss: 0.2631\n",
            "Epoch [39/100], Step [100/351], Loss: 0.3607\n",
            "Epoch [39/100], Step [200/351], Loss: 0.4195\n",
            "Epoch [39/100], Step [300/351], Loss: 0.2958\n",
            "Epoch [40/100], Step [100/351], Loss: 0.4591\n",
            "Epoch [40/100], Step [200/351], Loss: 0.2935\n",
            "Epoch [40/100], Step [300/351], Loss: 0.4317\n",
            "Epoch [41/100], Step [100/351], Loss: 0.3583\n",
            "Epoch [41/100], Step [200/351], Loss: 0.3080\n",
            "Epoch [41/100], Step [300/351], Loss: 0.5378\n",
            "Epoch [42/100], Step [100/351], Loss: 0.4771\n",
            "Epoch [42/100], Step [200/351], Loss: 0.3860\n",
            "Epoch [42/100], Step [300/351], Loss: 0.4596\n",
            "Epoch [43/100], Step [100/351], Loss: 0.2315\n",
            "Epoch [43/100], Step [200/351], Loss: 0.3331\n",
            "Epoch [43/100], Step [300/351], Loss: 0.2993\n",
            "Epoch [44/100], Step [100/351], Loss: 0.4501\n",
            "Epoch [44/100], Step [200/351], Loss: 0.2911\n",
            "Epoch [44/100], Step [300/351], Loss: 0.3091\n",
            "Epoch [45/100], Step [100/351], Loss: 0.3978\n",
            "Epoch [45/100], Step [200/351], Loss: 0.4295\n",
            "Epoch [45/100], Step [300/351], Loss: 0.3358\n",
            "Epoch [46/100], Step [100/351], Loss: 0.5007\n",
            "Epoch [46/100], Step [200/351], Loss: 0.3357\n",
            "Epoch [46/100], Step [300/351], Loss: 0.3039\n",
            "Epoch [47/100], Step [100/351], Loss: 0.4400\n",
            "Epoch [47/100], Step [200/351], Loss: 0.4268\n",
            "Epoch [47/100], Step [300/351], Loss: 0.3700\n",
            "Epoch [48/100], Step [100/351], Loss: 0.3582\n",
            "Epoch [48/100], Step [200/351], Loss: 0.6215\n",
            "Epoch [48/100], Step [300/351], Loss: 0.4207\n",
            "Epoch [49/100], Step [100/351], Loss: 0.5039\n",
            "Epoch [49/100], Step [200/351], Loss: 0.3376\n",
            "Epoch [49/100], Step [300/351], Loss: 0.3481\n",
            "Epoch [50/100], Step [100/351], Loss: 0.3315\n",
            "Epoch [50/100], Step [200/351], Loss: 0.3806\n",
            "Epoch [50/100], Step [300/351], Loss: 0.3841\n",
            "Epoch [51/100], Step [100/351], Loss: 0.5597\n",
            "Epoch [51/100], Step [200/351], Loss: 0.4306\n",
            "Epoch [51/100], Step [300/351], Loss: 0.3368\n",
            "Epoch [52/100], Step [100/351], Loss: 0.3961\n",
            "Epoch [52/100], Step [200/351], Loss: 0.3452\n",
            "Epoch [52/100], Step [300/351], Loss: 0.3393\n",
            "Epoch [53/100], Step [100/351], Loss: 0.5304\n",
            "Epoch [53/100], Step [200/351], Loss: 0.2211\n",
            "Epoch [53/100], Step [300/351], Loss: 0.3601\n",
            "Epoch [54/100], Step [100/351], Loss: 0.3782\n",
            "Epoch [54/100], Step [200/351], Loss: 0.2845\n",
            "Epoch [54/100], Step [300/351], Loss: 0.3263\n",
            "Epoch [55/100], Step [100/351], Loss: 0.2678\n",
            "Epoch [55/100], Step [200/351], Loss: 0.2175\n",
            "Epoch [55/100], Step [300/351], Loss: 0.3749\n",
            "Epoch [56/100], Step [100/351], Loss: 0.2642\n",
            "Epoch [56/100], Step [200/351], Loss: 0.3605\n",
            "Epoch [56/100], Step [300/351], Loss: 0.2961\n",
            "Epoch [57/100], Step [100/351], Loss: 0.2413\n",
            "Epoch [57/100], Step [200/351], Loss: 0.1870\n",
            "Epoch [57/100], Step [300/351], Loss: 0.5059\n",
            "Epoch [58/100], Step [100/351], Loss: 0.5467\n",
            "Epoch [58/100], Step [200/351], Loss: 0.1844\n",
            "Epoch [58/100], Step [300/351], Loss: 0.2584\n",
            "Epoch [59/100], Step [100/351], Loss: 0.4249\n",
            "Epoch [59/100], Step [200/351], Loss: 0.1472\n",
            "Epoch [59/100], Step [300/351], Loss: 0.3174\n",
            "Epoch [60/100], Step [100/351], Loss: 0.3040\n",
            "Epoch [60/100], Step [200/351], Loss: 0.2963\n",
            "Epoch [60/100], Step [300/351], Loss: 0.2037\n",
            "Epoch [61/100], Step [100/351], Loss: 0.1513\n",
            "Epoch [61/100], Step [200/351], Loss: 0.1692\n",
            "Epoch [61/100], Step [300/351], Loss: 0.2728\n",
            "Epoch [62/100], Step [100/351], Loss: 0.3479\n",
            "Epoch [62/100], Step [200/351], Loss: 0.2890\n",
            "Epoch [62/100], Step [300/351], Loss: 0.2987\n",
            "Epoch [63/100], Step [100/351], Loss: 0.2354\n",
            "Epoch [63/100], Step [200/351], Loss: 0.2208\n",
            "Epoch [63/100], Step [300/351], Loss: 0.2286\n",
            "Epoch [64/100], Step [100/351], Loss: 0.2175\n",
            "Epoch [64/100], Step [200/351], Loss: 0.1606\n",
            "Epoch [64/100], Step [300/351], Loss: 0.3698\n",
            "Epoch [65/100], Step [100/351], Loss: 0.2536\n",
            "Epoch [65/100], Step [200/351], Loss: 0.4026\n",
            "Epoch [65/100], Step [300/351], Loss: 0.3411\n",
            "Epoch [66/100], Step [100/351], Loss: 0.3872\n",
            "Epoch [66/100], Step [200/351], Loss: 0.2905\n",
            "Epoch [66/100], Step [300/351], Loss: 0.3146\n",
            "Epoch [67/100], Step [100/351], Loss: 0.1962\n",
            "Epoch [67/100], Step [200/351], Loss: 0.2396\n",
            "Epoch [67/100], Step [300/351], Loss: 0.1978\n",
            "Epoch [68/100], Step [100/351], Loss: 0.2648\n",
            "Epoch [68/100], Step [200/351], Loss: 0.3781\n",
            "Epoch [68/100], Step [300/351], Loss: 0.2569\n",
            "Epoch [69/100], Step [100/351], Loss: 0.2486\n",
            "Epoch [69/100], Step [200/351], Loss: 0.2504\n",
            "Epoch [69/100], Step [300/351], Loss: 0.2321\n",
            "Epoch [70/100], Step [100/351], Loss: 0.3807\n",
            "Epoch [70/100], Step [200/351], Loss: 0.1595\n",
            "Epoch [70/100], Step [300/351], Loss: 0.2292\n",
            "Epoch [71/100], Step [100/351], Loss: 0.3717\n",
            "Epoch [71/100], Step [200/351], Loss: 0.2931\n",
            "Epoch [71/100], Step [300/351], Loss: 0.2804\n",
            "Epoch [72/100], Step [100/351], Loss: 0.1952\n",
            "Epoch [72/100], Step [200/351], Loss: 0.1374\n",
            "Epoch [72/100], Step [300/351], Loss: 0.4520\n",
            "Epoch [73/100], Step [100/351], Loss: 0.2130\n",
            "Epoch [73/100], Step [200/351], Loss: 0.4624\n",
            "Epoch [73/100], Step [300/351], Loss: 0.1718\n",
            "Epoch [74/100], Step [100/351], Loss: 0.1728\n",
            "Epoch [74/100], Step [200/351], Loss: 1.1796\n",
            "Epoch [74/100], Step [300/351], Loss: 0.4358\n",
            "Epoch [75/100], Step [100/351], Loss: 0.4394\n",
            "Epoch [75/100], Step [200/351], Loss: 0.4602\n",
            "Epoch [75/100], Step [300/351], Loss: 0.2494\n",
            "Epoch [76/100], Step [100/351], Loss: 0.3904\n",
            "Epoch [76/100], Step [200/351], Loss: 0.3331\n",
            "Epoch [76/100], Step [300/351], Loss: 0.3571\n",
            "Epoch [77/100], Step [100/351], Loss: 0.3889\n",
            "Epoch [77/100], Step [200/351], Loss: 0.1900\n",
            "Epoch [77/100], Step [300/351], Loss: 0.2206\n",
            "Epoch [78/100], Step [100/351], Loss: 0.1772\n",
            "Epoch [78/100], Step [200/351], Loss: 0.1401\n",
            "Epoch [78/100], Step [300/351], Loss: 0.1742\n",
            "Epoch [79/100], Step [100/351], Loss: 0.2298\n",
            "Epoch [79/100], Step [200/351], Loss: 0.2153\n",
            "Epoch [79/100], Step [300/351], Loss: 0.1085\n",
            "Epoch [80/100], Step [100/351], Loss: 0.2565\n",
            "Epoch [80/100], Step [200/351], Loss: 0.4311\n",
            "Epoch [80/100], Step [300/351], Loss: 0.3899\n",
            "Epoch [81/100], Step [100/351], Loss: 0.1731\n",
            "Epoch [81/100], Step [200/351], Loss: 0.3383\n",
            "Epoch [81/100], Step [300/351], Loss: 0.2925\n",
            "Epoch [82/100], Step [100/351], Loss: 0.1631\n",
            "Epoch [82/100], Step [200/351], Loss: 0.1733\n",
            "Epoch [82/100], Step [300/351], Loss: 0.2835\n",
            "Epoch [83/100], Step [100/351], Loss: 0.2698\n",
            "Epoch [83/100], Step [200/351], Loss: 0.1859\n",
            "Epoch [83/100], Step [300/351], Loss: 0.1349\n",
            "Epoch [84/100], Step [100/351], Loss: 0.2004\n",
            "Epoch [84/100], Step [200/351], Loss: 0.1447\n",
            "Epoch [84/100], Step [300/351], Loss: 0.4288\n",
            "Epoch [85/100], Step [100/351], Loss: 0.3118\n",
            "Epoch [85/100], Step [200/351], Loss: 0.3134\n",
            "Epoch [85/100], Step [300/351], Loss: 0.3420\n",
            "Epoch [86/100], Step [100/351], Loss: 0.5794\n",
            "Epoch [86/100], Step [200/351], Loss: 0.3576\n",
            "Epoch [86/100], Step [300/351], Loss: 0.2406\n",
            "Epoch [87/100], Step [100/351], Loss: 0.1536\n",
            "Epoch [87/100], Step [200/351], Loss: 0.3068\n",
            "Epoch [87/100], Step [300/351], Loss: 0.2235\n",
            "Epoch [88/100], Step [100/351], Loss: 0.9413\n",
            "Epoch [88/100], Step [200/351], Loss: 0.7277\n",
            "Epoch [88/100], Step [300/351], Loss: 0.3678\n",
            "Epoch [89/100], Step [100/351], Loss: 0.3369\n",
            "Epoch [89/100], Step [200/351], Loss: 0.3403\n",
            "Epoch [89/100], Step [300/351], Loss: 0.2893\n",
            "Epoch [90/100], Step [100/351], Loss: 0.2419\n",
            "Epoch [90/100], Step [200/351], Loss: 0.2357\n",
            "Epoch [90/100], Step [300/351], Loss: 0.1746\n",
            "Epoch [91/100], Step [100/351], Loss: 0.3390\n",
            "Epoch [91/100], Step [200/351], Loss: 0.2444\n",
            "Epoch [91/100], Step [300/351], Loss: 0.2482\n",
            "Epoch [92/100], Step [100/351], Loss: 0.1126\n",
            "Epoch [92/100], Step [200/351], Loss: 0.1732\n",
            "Epoch [92/100], Step [300/351], Loss: 0.4683\n",
            "Epoch [93/100], Step [100/351], Loss: 0.2819\n",
            "Epoch [93/100], Step [200/351], Loss: 0.3185\n",
            "Epoch [93/100], Step [300/351], Loss: 0.1956\n",
            "Epoch [94/100], Step [100/351], Loss: 0.1932\n",
            "Epoch [94/100], Step [200/351], Loss: 0.1097\n",
            "Epoch [94/100], Step [300/351], Loss: 0.4184\n",
            "Epoch [95/100], Step [100/351], Loss: 0.2168\n",
            "Epoch [95/100], Step [200/351], Loss: 0.3233\n",
            "Epoch [95/100], Step [300/351], Loss: 0.2023\n",
            "Epoch [96/100], Step [100/351], Loss: 0.1816\n",
            "Epoch [96/100], Step [200/351], Loss: 0.1922\n",
            "Epoch [96/100], Step [300/351], Loss: 0.2117\n",
            "Epoch [97/100], Step [100/351], Loss: 0.2689\n",
            "Epoch [97/100], Step [200/351], Loss: 0.1626\n",
            "Epoch [97/100], Step [300/351], Loss: 0.9367\n",
            "Epoch [98/100], Step [100/351], Loss: 0.3156\n",
            "Epoch [98/100], Step [200/351], Loss: 0.2395\n",
            "Epoch [98/100], Step [300/351], Loss: 0.3422\n",
            "Epoch [99/100], Step [100/351], Loss: 0.1664\n",
            "Epoch [99/100], Step [200/351], Loss: 0.2184\n",
            "Epoch [99/100], Step [300/351], Loss: 0.1850\n",
            "Epoch [100/100], Step [100/351], Loss: 0.3475\n",
            "Epoch [100/100], Step [200/351], Loss: 0.2698\n",
            "Epoch [100/100], Step [300/351], Loss: 0.1205\n"
          ]
        }
      ],
      "source": [
        "model = model.to(device)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_dataloader):\n",
        "        # Move the input tensors, model, and optimizer to the GPU\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if (i+1) % 100 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                   .format(epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.item()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrjBIk51CAAV",
        "outputId": "7d6773d5-fcc2-4736-b5b0-9454fccb362a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation accuracy: 0.8636\n"
          ]
        }
      ],
      "source": [
        "# Test the model on the validation dataset\n",
        "model = model.to(device)\n",
        "\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in val_dataloader:\n",
        "        # Move the input tensors, model, and optimizer to the GPU\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print('Validation accuracy: {:.4f}'.format(accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KaTKBNyMdcPl"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO8mhAiOtIUyKqwO0bSqXR0",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7edb6c23502f40f2a687206c0128fd16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6293a9e370c3489d865cd669653364cd",
              "IPY_MODEL_b98fe8f73032479ab17369c353268d46",
              "IPY_MODEL_25249f861ce74e3481ae3ea116c281a2"
            ],
            "layout": "IPY_MODEL_b13e0796cee149f284270f7b50a59c25"
          }
        },
        "6293a9e370c3489d865cd669653364cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8aa02ca90fb471b99796b3c3aef2a3f",
            "placeholder": "​",
            "style": "IPY_MODEL_0fde248261c448cca20dbdef69b24c5b",
            "value": "100%"
          }
        },
        "b98fe8f73032479ab17369c353268d46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82abaa49ad584d7180889c22c5288a7e",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e30ce103f87e45a8bf462ee7ad8c24df",
            "value": 170498071
          }
        },
        "25249f861ce74e3481ae3ea116c281a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e7a041fcf344c71ab82d41bb50162de",
            "placeholder": "​",
            "style": "IPY_MODEL_3a240b8d66dc4faea5ecae8db7756d8e",
            "value": " 170498071/170498071 [00:03&lt;00:00, 54831284.72it/s]"
          }
        },
        "b13e0796cee149f284270f7b50a59c25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8aa02ca90fb471b99796b3c3aef2a3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fde248261c448cca20dbdef69b24c5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82abaa49ad584d7180889c22c5288a7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e30ce103f87e45a8bf462ee7ad8c24df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4e7a041fcf344c71ab82d41bb50162de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a240b8d66dc4faea5ecae8db7756d8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}